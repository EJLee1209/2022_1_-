{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/5xxknbnj0sx3x_39kz04q09w0000gn/T/ipykernel_56018/3920414413.py:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  cnn.fit_generator(generator.flow(x_train,y_train,batch_size=128),epochs=30,validation_data=(x_test,y_test),verbose=2)\n",
      "2022-05-24 22:15:52.304456: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-24 22:15:57.662241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 6s - loss: 1.4809 - accuracy: 0.3430 - val_loss: 1.3603 - val_accuracy: 0.4560 - 6s/epoch - 192ms/step\n",
      "Epoch 2/30\n",
      "32/32 - 5s - loss: 1.2209 - accuracy: 0.5250 - val_loss: 1.0422 - val_accuracy: 0.6360 - 5s/epoch - 172ms/step\n",
      "Epoch 3/30\n",
      "32/32 - 5s - loss: 1.0389 - accuracy: 0.6095 - val_loss: 0.9936 - val_accuracy: 0.6280 - 5s/epoch - 171ms/step\n",
      "Epoch 4/30\n",
      "32/32 - 6s - loss: 0.9092 - accuracy: 0.6595 - val_loss: 0.7048 - val_accuracy: 0.7350 - 6s/epoch - 177ms/step\n",
      "Epoch 5/30\n",
      "32/32 - 6s - loss: 0.7808 - accuracy: 0.7100 - val_loss: 0.6679 - val_accuracy: 0.7510 - 6s/epoch - 172ms/step\n",
      "Epoch 6/30\n",
      "32/32 - 5s - loss: 0.7491 - accuracy: 0.7205 - val_loss: 0.6439 - val_accuracy: 0.7520 - 5s/epoch - 170ms/step\n",
      "Epoch 7/30\n",
      "32/32 - 5s - loss: 0.6611 - accuracy: 0.7490 - val_loss: 0.6908 - val_accuracy: 0.7410 - 5s/epoch - 169ms/step\n",
      "Epoch 8/30\n",
      "32/32 - 5s - loss: 0.6228 - accuracy: 0.7595 - val_loss: 0.5393 - val_accuracy: 0.7960 - 5s/epoch - 170ms/step\n",
      "Epoch 9/30\n",
      "32/32 - 5s - loss: 0.5647 - accuracy: 0.7868 - val_loss: 0.5185 - val_accuracy: 0.7990 - 5s/epoch - 171ms/step\n",
      "Epoch 10/30\n",
      "32/32 - 5s - loss: 0.6282 - accuracy: 0.7575 - val_loss: 0.5588 - val_accuracy: 0.7840 - 5s/epoch - 169ms/step\n",
      "Epoch 11/30\n",
      "32/32 - 5s - loss: 0.5333 - accuracy: 0.7968 - val_loss: 0.4829 - val_accuracy: 0.8130 - 5s/epoch - 171ms/step\n",
      "Epoch 12/30\n",
      "32/32 - 5s - loss: 0.5083 - accuracy: 0.8000 - val_loss: 0.4425 - val_accuracy: 0.8250 - 5s/epoch - 169ms/step\n",
      "Epoch 13/30\n",
      "32/32 - 5s - loss: 0.4875 - accuracy: 0.8155 - val_loss: 0.4888 - val_accuracy: 0.8160 - 5s/epoch - 169ms/step\n",
      "Epoch 14/30\n",
      "32/32 - 5s - loss: 0.4806 - accuracy: 0.8168 - val_loss: 0.4175 - val_accuracy: 0.8450 - 5s/epoch - 170ms/step\n",
      "Epoch 15/30\n",
      "32/32 - 6s - loss: 0.5119 - accuracy: 0.8033 - val_loss: 0.4943 - val_accuracy: 0.8120 - 6s/epoch - 178ms/step\n",
      "Epoch 16/30\n",
      "32/32 - 6s - loss: 0.4418 - accuracy: 0.8300 - val_loss: 0.4395 - val_accuracy: 0.8320 - 6s/epoch - 180ms/step\n",
      "Epoch 17/30\n",
      "32/32 - 6s - loss: 0.4022 - accuracy: 0.8488 - val_loss: 0.4283 - val_accuracy: 0.8410 - 6s/epoch - 176ms/step\n",
      "Epoch 18/30\n",
      "32/32 - 6s - loss: 0.4025 - accuracy: 0.8543 - val_loss: 0.4303 - val_accuracy: 0.8390 - 6s/epoch - 176ms/step\n",
      "Epoch 19/30\n",
      "32/32 - 6s - loss: 0.4192 - accuracy: 0.8408 - val_loss: 0.3785 - val_accuracy: 0.8600 - 6s/epoch - 175ms/step\n",
      "Epoch 20/30\n",
      "32/32 - 6s - loss: 0.3683 - accuracy: 0.8593 - val_loss: 0.5161 - val_accuracy: 0.8060 - 6s/epoch - 176ms/step\n",
      "Epoch 21/30\n",
      "32/32 - 6s - loss: 0.3694 - accuracy: 0.8598 - val_loss: 0.6408 - val_accuracy: 0.7660 - 6s/epoch - 178ms/step\n",
      "Epoch 22/30\n",
      "32/32 - 6s - loss: 0.3894 - accuracy: 0.8460 - val_loss: 0.4705 - val_accuracy: 0.8210 - 6s/epoch - 180ms/step\n",
      "Epoch 23/30\n",
      "32/32 - 6s - loss: 0.3582 - accuracy: 0.8568 - val_loss: 0.3882 - val_accuracy: 0.8570 - 6s/epoch - 179ms/step\n",
      "Epoch 24/30\n",
      "32/32 - 6s - loss: 0.3162 - accuracy: 0.8835 - val_loss: 0.3674 - val_accuracy: 0.8790 - 6s/epoch - 181ms/step\n",
      "Epoch 25/30\n",
      "32/32 - 6s - loss: 0.3007 - accuracy: 0.8835 - val_loss: 0.4146 - val_accuracy: 0.8550 - 6s/epoch - 181ms/step\n",
      "Epoch 26/30\n",
      "32/32 - 6s - loss: 0.3200 - accuracy: 0.8780 - val_loss: 0.4646 - val_accuracy: 0.8420 - 6s/epoch - 181ms/step\n",
      "Epoch 27/30\n",
      "32/32 - 6s - loss: 0.3236 - accuracy: 0.8733 - val_loss: 0.4669 - val_accuracy: 0.8290 - 6s/epoch - 182ms/step\n",
      "Epoch 28/30\n",
      "32/32 - 6s - loss: 0.2985 - accuracy: 0.8888 - val_loss: 0.6422 - val_accuracy: 0.7890 - 6s/epoch - 181ms/step\n",
      "Epoch 29/30\n",
      "32/32 - 6s - loss: 0.2936 - accuracy: 0.8840 - val_loss: 0.3947 - val_accuracy: 0.8690 - 6s/epoch - 184ms/step\n",
      "Epoch 30/30\n",
      "32/32 - 6s - loss: 0.2788 - accuracy: 0.8903 - val_loss: 0.3522 - val_accuracy: 0.8820 - 6s/epoch - 182ms/step\n",
      "정확률은 88.20000290870667\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train.csv 파일 읽어오기 (label)\n",
    "f= open('train.csv','r')\n",
    "label_data=pd.read_csv(f,header=0)\n",
    "seq=label_data[['label']].to_numpy()\n",
    "\n",
    "# 이미지 읽어오기 (data)\n",
    "images = np.zeros((5000,64,64,3))\n",
    "for i in range(5000):\n",
    "    images[i]=image.load_img('train/train_img_{0}.jpg'.format(i))\n",
    "\n",
    "# 훈련집합과 테스트집합으로 분할\n",
    "x_train,x_test,y_train,y_test=train_test_split(images,seq,stratify=seq,test_size=0.2)\n",
    "\n",
    "x_train=x_train.astype(np.float32)/255.0 # 정규화\n",
    "x_test=x_test.astype(np.float32)/255.0\n",
    "y_train=tf.keras.utils.to_categorical(y_train,5) # 원핫코드로 변환(레이블은 0,1,2,3,4 총 5개 부류)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,5)\n",
    "\n",
    "# 드랍아웃이 없는게 성능이 더 좋음\n",
    "cnn=Sequential()\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(64,64,3)))\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
    "cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
    "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(512,activation='relu'))\n",
    "cnn.add(Dense(5,activation='softmax'))\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "# 데이터 증대\n",
    "generator=ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,horizontal_flip=True)\n",
    "cnn.fit_generator(generator.flow(x_train,y_train,batch_size=128),epochs=30,validation_data=(x_test,y_test),verbose=2)\n",
    "\n",
    "res=cnn.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"정확률은\",res[1]*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('final_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 62, 62, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 30, 30, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 26, 26, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 13, 13, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 10816)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               5538304   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,653,445\n",
      "Trainable params: 5,653,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 22:24:00.117180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확률은 92.80000329017639\n"
     ]
    }
   ],
   "source": [
    "cnn=tf.keras.models.load_model(\"final_cnn.h5\")\n",
    "cnn.summary()\n",
    "\n",
    "f= open('train.csv','r')\n",
    "label_data=pd.read_csv(f,header=0)\n",
    "seq=label_data[['label']].to_numpy()\n",
    "\n",
    "# 이미지 읽어오기 (data)\n",
    "images = np.zeros((5000,64,64,3))\n",
    "for i in range(5000):\n",
    "    images[i]=image.load_img('train/train_img_{0}.jpg'.format(i))\n",
    "\n",
    "# 훈련집합과 테스트집합으로 분할\n",
    "x_train,x_test,y_train,y_test=train_test_split(images,seq,stratify=seq,test_size=0.2)\n",
    "\n",
    "x_train=x_train.astype(np.float32)/255.0 # 정규화\n",
    "x_test=x_test.astype(np.float32)/255.0\n",
    "y_train=tf.keras.utils.to_categorical(y_train,5) # 원핫코드로 변환(레이블은 0,1,2,3,4 총 5개 부류)\n",
    "y_test=tf.keras.utils.to_categorical(y_test,5)\n",
    "\n",
    "res=cnn.evaluate(x_test,y_test,verbose=0)\n",
    "print(\"정확률은\",res[1]*100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d301370be49b570484a94918bd639cb06cef27e8a96a5878d8b8b4c57f819534"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
